{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc7a578",
   "metadata": {},
   "source": [
    "# **Modelos e Valida√ß√£o ‚Äî M√≥dulo 2, Notebook 1/4**\n",
    "\n",
    "---\n",
    "\n",
    "## √çndice\n",
    "\n",
    "1. [Modelos Preditivos](#modelos-preditivos)\n",
    "2. [Tradeoff Bias-Vari√¢ncia](#bias-variancia)\n",
    "3. [Valida√ß√£o Cruzada](#validacao-cruzada)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76499392",
   "metadata": {},
   "source": [
    "<a id='modelos-preditivos'></a>\n",
    "\n",
    "## **O que √© um Modelo Preditivo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1f1ce",
   "metadata": {},
   "source": [
    "Um modelo preditivo √© um tipo de modelo de machine learning que tem como objetivo principal fazer previs√µes sobre novos dados com base em padr√µes aprendidos a partir de dados hist√≥ricos.\n",
    "\n",
    "---\n",
    "\n",
    "Esses modelos utilizam padr√µes extra√≠dos dos dados para fazer previs√µes sobre novas observa√ß√µes. Em termos formais, esses modelos buscam aprender uma fun√ß√£o $$f: x_{i} \\in X \\rightarrow Y$$ que relacione os vetores de caracter√≠sticas $x_{i} \\in X$ com a vari√°vel alvo $Y$, de forma que seja poss√≠vel estimar um $Y$ para um novo $x_{i} \\in X$ n√£o observado anteriormente.\n",
    "\n",
    "---\n",
    "\n",
    "Os modelos preditivos podem ser utilizados para diferentes tipos de tarefas, como prever se um cliente pagar√° um empr√©stimo (classifica√ß√£o), estimar o valor de um im√≥vel (regress√£o) ou antecipar o comportamento de uma s√©rie temporal (como pre√ßos de ativos financeiros).\n",
    "\n",
    "No entanto, as abordagens para construir esse tipo de modelo variam bastante, dependendo da forma como os dados s√£o tratados e da estrat√©gia utilizada para ajustar os par√¢metros do modelo. Podemos dividir os modelos preditivos em algumas categorias principais, s√£o elas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3be2f",
   "metadata": {},
   "source": [
    "### **1. Modelos Estat√≠sticos e Probabil√≠sticos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f5cd0",
   "metadata": {},
   "source": [
    "Esses modelos assumem que os dados seguem uma distribui√ß√£o probabil√≠stica espec√≠fica e ajustam seus par√¢metros para maximizar a verossimilhan√ßa dos dados observados.\n",
    "\n",
    "‚úÖ **Objetivo:** Estimar a distribui√ß√£o dos dados e inferir a rela√ß√£o entre as vari√°veis.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- Regress√£o Linear: Assume que a rela√ß√£o entre as vari√°veis √© linear e que os res√≠duos seguem uma distribui√ß√£o normal.\n",
    "\n",
    "- Regress√£o Log√≠stica: Usa a fun√ß√£o sigmoide para modelar probabilidades em problemas de classifica√ß√£o bin√°ria.\n",
    "\n",
    "- Na√Øve Bayes: Baseia-se na regra de Bayes e assume independ√™ncia condicional entre os atributos.\n",
    "\n",
    "üìå **Diferencial:** Esses modelos s√£o baseados em conceitos estat√≠sticos bem definidos e geralmente interpret√°veis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b7606b",
   "metadata": {},
   "source": [
    "### **2. Modelos Baseados em Otimiza√ß√£o**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6ed06",
   "metadata": {},
   "source": [
    "Esses modelos aprendem a fun√ß√£o $f$ otimizando uma m√©trica espec√≠fica, sem necessariamente assumir uma distribui√ß√£o subjacente dos dados.\n",
    "\n",
    "‚úÖ **Objetivo:** Encontrar um modelo que minimize uma fun√ß√£o de erro ou maximize uma margem de separa√ß√£o.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- SVM (M√°quinas de Vetores de Suporte): Maximiza a margem entre as classes em problemas de classifica√ß√£o.\n",
    "\n",
    "- Redes Neurais (MLPs cl√°ssicas): Ajustam pesos para minimizar um erro atrav√©s do gradiente descendente.\n",
    "\n",
    "üìå **Diferencial:** Baseiam-se em t√©cnicas num√©ricas de otimiza√ß√£o e n√£o exigem uma suposi√ß√£o expl√≠cita sobre a distribui√ß√£o dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523055d9",
   "metadata": {},
   "source": [
    "### **3. Modelos Baseados em Particionamento de Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119b38b",
   "metadata": {},
   "source": [
    "Esses modelos criam regras para dividir os dados em subconjuntos homog√™neos, organizando-os hierarquicamente.\n",
    "\n",
    "‚úÖ **Objetivo:** Criar regras de decis√£o que segmentem os dados em diferentes categorias.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- √Årvores de Decis√£o: Criam um conjunto de regras sequenciais que levam a decis√µes.\n",
    "\n",
    "- Random Forests: Conjunto de √°rvores de decis√£o para aumentar a robustez.\n",
    "\n",
    "üìå **Diferencial:** S√£o f√°ceis de interpretar e n√£o exigem transforma√ß√µes matem√°ticas complexas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811914f",
   "metadata": {},
   "source": [
    "### **4. Modelos Baseados em Agrupamento (Clustering)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f7d89",
   "metadata": {},
   "source": [
    "Modelos que tentam encontrar padr√µes e estruturas nos dados sem r√≥tulos supervisionados.\n",
    "\n",
    "‚úÖ **Objetivo:** Agrupar os dados de forma a maximizar a semelhan√ßa dentro dos clusters e minimizar entre os clusters.\n",
    "\n",
    "**Exemplos:**\n",
    "\n",
    "- K-Means: Baseado na minimiza√ß√£o da soma das dist√¢ncias dos pontos ao centro do cluster.\n",
    "\n",
    "- DBSCAN: Detecta clusters com base na densidade dos dados.\n",
    "\n",
    "üìå **Diferencial:** √öteis para an√°lise explorat√≥ria e segmenta√ß√£o de dados sem supervis√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3c5b4",
   "metadata": {},
   "source": [
    "### **5. Modelos Baseados em Inst√¢ncias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8096fe",
   "metadata": {},
   "source": [
    "Esses modelos fazem previs√µes baseadas nos exemplos mais pr√≥ximos no conjunto de treinamento, sem construir explicitamente uma fun√ß√£o generalizada durante o aprendizado.\n",
    "\n",
    "‚úÖ **Objetivo:** Utilizar diretamente os dados observados para fazer previs√µes sem uma fase expl√≠cita de aprendizado de par√¢metros.\n",
    "\n",
    "**Exemplo:**\n",
    "    \n",
    "- KNN (K-Nearest Neighbors): Classifica ou estima valores com base nos $k$ vizinhos mais pr√≥ximos.\n",
    "\n",
    "üìå Diferencial: S√£o conhecidos como modelos pregui√ßosos (lazy learners) porque n√£o possuem uma fase expl√≠cita de treinamento; todo o esfor√ßo computacional ocorre no momento da previs√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cebf18",
   "metadata": {},
   "source": [
    "### **A Import√¢ncia da Amostra de Treinamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8808a",
   "metadata": {},
   "source": [
    "No fim das contas, modelos preditivos tentam encontrar uma fun√ß√£o matem√°tica que capture a rela√ß√£o entre as vari√°veis de entrada (caracter√≠sticas) e a vari√°vel de sa√≠da (o que queremos prever). Essa fun√ß√£o pode ser vista como uma aproxima√ß√£o da verdadeira rela√ß√£o existente nos dados. No entanto, os dados usados para treinar o modelo representam apenas uma amostra de um conjunto muito maior e desconhecido. Se essa amostra for pequena, enviesada ou n√£o representativa, o modelo pode aprender padr√µes artificiais que n√£o se repetem em novos dados ‚Äî um problema conhecido como overfitting.\n",
    "\n",
    "Diferentes modelos fazem suposi√ß√µes distintas sobre essa rela√ß√£o. Modelos estat√≠sticos assumem que os dados seguem certas distribui√ß√µes probabil√≠sticas, enquanto modelos baseados em otimiza√ß√£o simplesmente ajustam fun√ß√µes para melhor se encaixar nos exemplos observados, sem pressupor uma estrutura fixa. Em ambos os casos, a qualidade da amostra influencia diretamente a capacidade do modelo de fazer boas previs√µes.\n",
    "\n",
    "Por isso, ao treinar um modelo, √© essencial garantir que os dados de entrada representem bem o fen√¥meno que estamos tentando modelar. M√©todos como valida√ß√£o cruzada, regulariza√ß√£o e aumento da diversidade dos dados ajudam a reduzir vieses e melhorar a capacidade do modelo de generalizar para novas situa√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d808e63",
   "metadata": {},
   "source": [
    "<a id='bias-variancia'></a>\n",
    "\n",
    "## **Tradeoff entre Bias e Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d0d4d",
   "metadata": {},
   "source": [
    "No contexto de machine learning, bias e variance s√£o conceitos centrais para entender o erro total de um modelo e avaliar sua capacidade de generaliza√ß√£o. Esses componentes descrevem como o modelo se comporta ao lidar com novos dados, ou seja, dados que n√£o foram usados durante o treinamento, e ajudam a identificar as causas de diferentes tipos de erro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a72cbb",
   "metadata": {},
   "source": [
    "### **Explicando o Bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57defb9b",
   "metadata": {},
   "source": [
    "O bias est√° associado √† incapacidade do modelo de captar as complexidades subjacentes nos dados. Modelos com alto bias fazem suposi√ß√µes simplificadas, resultando em um desempenho ruim tanto nos dados de treino quanto nos de teste. Esse comportamento caracteriza o subajuste (underfiting), quando o modelo n√£o consegue representar adequadamente as rela√ß√µes reais nos dados.\n",
    "\n",
    "Caracter√≠sticas do Bias:\n",
    "- Modelos com bias altos geralmente s√£o simples. Um exemplo √© a regress√£o linear aplicada quando os dados possuem rela√ß√µes **n√£o-lineares**\n",
    "- Ocorre quando o modelo subestima a complexidade das rela√ß√µes entre os dados\n",
    "- Est√° associada com baixa acur√°cia tanto nos dados de treino quanto nos dados de teste.\n",
    "\n",
    "A imagem abaixo deixa mais claro uma situa√ß√£o de um modelo com alto bias.\n",
    "\n",
    "<p align='center'>\n",
    "<img src=\"https://sigmoidal.ai/wp-content/uploads/2023/11/621609a7e64cfb63781a0426_24-300x200.png\" width=\"400\"></img>\n",
    "</p>\n",
    "\n",
    "Perceba que claramente h√° uma rela√ß√£o n√£o-linear entre os dados. Por√©m, o modelo tenta ajustar uma reta ao conjunto de dados, n√£o capturando toda a complexidade envolvida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6325453",
   "metadata": {},
   "source": [
    "### **Defini√ß√£o formal de Bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac72c0",
   "metadata": {},
   "source": [
    "O bias mede o erro sistem√°tico do modelo. Formalmente, ele se refere √† diferen√ßa entre o valor m√©dio das predi√ß√µes do modelo e o valor verdadeiro que estamos tentando prever. Matematicamente, para uma vari√°vel-alvo y, com base em entradas x, o bias √© definido como:\n",
    "\n",
    "$$\n",
    "\tBias(\\hat{f}(x)) = \\mathbb{E}[\\hat{f}(x)] - f(x)\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $E[\\hat{f}(x)]$ √© o valor esperado das predi√ß√µes do modelo (considerando diferentes amostras de treino).\n",
    "- $f(x)$ √© o verdadeiro mapeamento subjacente (fun√ß√£o real que gera os dados)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d04c5a",
   "metadata": {},
   "source": [
    "### **Explicando a Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18d627",
   "metadata": {},
   "source": [
    "Por outro lado, a variancia reflete a sensibilidade do modelo √†s flutua√ß√µes nos dados de treino. Modelos com alta variancia n√£o apenas aprendem os padr√µes gerais, mas tamb√©m o ru√≠do espec√≠fico dos dados de treino. Isso resulta em um excelente desempenho nos dados de treino, mas um desempenho ruim em novos dados, caracterizando o superajuste (overfitting). \n",
    "\n",
    "Caracter√≠sticas da Variancia:\n",
    "\n",
    "- Modelos com variancia alta s√£o geralmente complexos, como √°rvores de decis√£o profundas ou redes neurais complexas treinadas com poucos dados.\n",
    "- Ocorre quando o modelo se ajusta excessivamente aos dados de treinamento.\n",
    "- Resulta em alta acur√°cia no **treinamento**, mas baixa acur√°cia em dados de **teste**, pois o modelo n√£o generaliza bem.\n",
    "\n",
    "\n",
    "A imagem abaixo mostra um exemplo de uma caso com alta variancia (overfitting):\n",
    "<p align='center'>\n",
    "<img src=\"https://cdn.prod.website-files.com/5fb24a974499e90dae242d98/621608ae7abbdc500080ef96_23.png\" width=\"400\"></img>\n",
    "</p>\n",
    "\n",
    "Neste caso, perceba que o modelo foca n√£o nas relac√µes fundamentais entre os dados, mas sim no r√∫ido espec√≠ficio dos dados de treino. Se formos aplicar esse modelo a uma outra amostra de dados que n√£o seja a de treino, o desempenho ser√° muito baixo, pois √© como se o modelo tivesse apenas memorizado o conjunto de treinamento.\n",
    "\n",
    "üí° **Dica**: Lembra daquela prova em que voc√™ teve pouco tempo de estudar e dois dias antes da prova bate aquele desespero? O que voc√™ faz? N√£o d√° tempo de entender todo o conte√∫do em t√£o pouco tempo.\n",
    "\n",
    "Uma alternativa nesse cen√°rio √© decorar aquela lista que o professor passou para estudo. Vai que cai uma quest√£o igualzinha n√©? \n",
    "\n",
    "Esse √© um caso em que voc√™ est√° em um overfitting!! Voc√™ pode ser capaz de responder cada quest√£o da lista de bate pronto, mas voc√™ n√£o entendeu o conte√∫do de fato, se houver alguma pergunta diferente, voc√™ n√£o saber√° responder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d62d9",
   "metadata": {},
   "source": [
    "### **Defini√ß√£o formal de Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d05d5",
   "metadata": {},
   "source": [
    " A variancia mede a sensibilidade do modelo √†s flutua√ß√µes nos dados de treino. Ela descreve o quanto as predi√ß√µes do modelo variam em rela√ß√£o √† m√©dia das predi√ß√µes quando o modelo √© treinado com diferentes amostras de treino. Formalmente, a variancia √© definida como:\n",
    "\n",
    "$$\n",
    "\tVar(\\hat{f}(x)) = \\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^{2}] \n",
    "$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "- $\\hat{f}(x)$ √© a predi√ß√£o do modelo.\n",
    "- $\\mathbb{E}[\\hat{f}(x)]$ √© o valor esperado das predi√ß√µes do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452ef91",
   "metadata": {},
   "source": [
    "### **Explicando o Tradeoff entre Bias e Vari√¢ncia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c041499",
   "metadata": {},
   "source": [
    "Fundamentalmente, a quest√£o de encontrar \"o melhor modelo\" se refere a encontrar um ponto √≥timo no trade-off entre bias e variancia\n",
    "\n",
    "A capacidade de generaliza√ß√£o de um modelo depende de encontrar um equil√≠brio entre bias e variancia. Um modelo com alto bias √© muito simples e subajusta os dados, enquanto um modelo com alta variancia √© excessivamente complexo e superajusta os dados de treino.\n",
    "\n",
    "O trade-off entre bias e variance refere-se ao equil√≠brio necess√°rio entre simplicidade e complexidade do modelo para alcan√ßar a melhor performance poss√≠vel.\n",
    "- üî∫Aumentar a complexidade de um modelo reduz o bias, mas aumenta a vari√¢ncia.\n",
    "- üîªSimplificar o modelo reduz a vari√¢ncia, mas aumenta o bias.\n",
    "\n",
    "O objetivo √© encontrar um ponto de equil√≠brio onde o modelo n√£o seja nem muito simples (evitando underfitting), nem excessivamente complexo (evitando overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a78ca",
   "metadata": {},
   "source": [
    "<a id='validacao-cruzada'></a>\n",
    "\n",
    "## **Valida√ß√£o Cruzada**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2931b",
   "metadata": {},
   "source": [
    "A valida√ß√£o cruzada √© uma t√©cnica que avalia um modelo dividindo os dados em m√∫ltiplos subconjuntos, treinando o modelo em um subconjunto e testando-o nos restantes de forma iterativa. Isso tem como intuito avaliar como o modelo se comporta com dados in√©ditos, simulando uma situa√ß√£o de uso real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfae92",
   "metadata": {},
   "source": [
    "#### *Dados i.i.d. (sem ordem temporal relevante)*\n",
    "\n",
    "Quando as observa√ß√µes podem ser assumidas **independentes e identicamente distribu√≠das (i.i.d.)** e n√£o h√° depend√™ncia temporal ou estrutural relevante, usa-se a CV (Cross Validation/Valida√ß√£o Cruzada) padr√£o:\n",
    "\n",
    "- **K-Fold CV (aleat√≥ria):** particiona $ \\mathcal{D} $ em $K$ blocos aproximadamente do mesmo tamanho. Em cada itera√ß√£o $k$, treina-se no complemento do bloco $k$ e avalia-se no bloco $k$. A estimativa de desempenho √© a m√©dia (ou mediana) das m√©tricas ao longo dos $K$ folds.  \n",
    "  $$\n",
    "  \\widehat{\\text{Score}} = \\frac{1}{K} \\sum_{k=1}^K \\text{score}\\big(f^{(-k)}, \\mathcal{D}^{(k)}\\big)\n",
    "  $$\n",
    "  onde $ f^{(-k)} $ √© o modelo treinado sem o fold $k$ e $ \\mathcal{D}^{(k)} $ √© o conjunto de valida√ß√£o do fold $k$.\n",
    "\n",
    "- **Estratificada (classifica√ß√£o):** preserva a propor√ß√£o de classes em cada fold.\n",
    "- **Group K-Fold / Leave-One-Group-Out:** evita vazamento entre grupos correlacionados (mesmo usu√°rio, empresa, etc.).\n",
    "\n",
    "> **Observa√ß√£o:** Em dados i.i.d., √© comum embaralhar as amostras antes de gerar os folds; em s√©ries temporais, **n√£o**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b38789",
   "metadata": {},
   "source": [
    "#### *S√©ries temporais (ordem temporal relevante)*\n",
    "\n",
    "Quando h√° depend√™ncia temporal (autocorrela√ß√£o, tend√™ncia, sazonalidade) ou risco de **vazamento temporal**, a K-Fold aleat√≥ria **n√£o √© adequada**. Em vez disso, usam-se parti√ß√µes que **respeitam a ordem** e imp√µem que o **treino seja estritamente anterior** ao **valida√ß√£o/teste**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c05bd",
   "metadata": {},
   "source": [
    "##### Valida√ß√£o ‚Äúrolling origin‚Äù (walk-forward) com janela **expansiva**\n",
    "- Em cada itera√ß√£o $t$, o modelo treina em $[1, t]$ e valida em $(t, t+h]$ (t√≠pico $h=1$ para ‚Äúum passo √† frente‚Äù).\n",
    "- Sequ√™ncia de splits:\n",
    "  $$\n",
    "  \\text{Train}_1 = [1{:}t_1],\\ \\text{Val}_1 = (t_1{:}t_1+h];\\quad\n",
    "  \\text{Train}_2 = [1{:}t_2],\\ \\text{Val}_2 = (t_2{:}t_2+h];\\ \\ldots\n",
    "  $$\n",
    "- **Propriedades:** usa toda a hist√≥ria acumulada; adequado quando a rela√ß√£o $y_t \\mid x_{\\le t}$ √© relativamente est√°vel no tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca22d9a",
   "metadata": {},
   "source": [
    "##### Valida√ß√£o ‚Äúrolling window‚Äù com janela **deslizante (fixa)**\n",
    "- Mant√©m uma janela fixa de treino de comprimento $W$: treina em $[t-W+1, t]$ e valida em $(t, t+h]$.\n",
    "- **Propriedades:** d√° mais √™nfase √† din√¢mica recente; √∫til em ambientes com **n√£o-estacionaridade**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410db2f9",
   "metadata": {},
   "source": [
    "##### **Blocked / Purged K-Fold** para s√©ries temporais\n",
    "- Divide a s√©rie em $K$ blocos **cont√≠guos** (sem embaralhar). Em cada itera√ß√£o, um bloco √© valida√ß√£o e os demais (anteriores) comp√µem o treino.  \n",
    "- **Purging / Embargo:** insere-se um **gap temporal** entre as janelas de treino e valida√ß√£o para evitar vazamento por **sobreposi√ß√£o de janelas** ou **labels** (comum em finan√ßas). Se o label usa informa√ß√µes at√© $t+\\ell$, imp√µe-se um embargo $g \\ge \\ell$ entre o fim do treino e o in√≠cio da valida√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b426d340",
   "metadata": {},
   "source": [
    "##### Agrega√ß√£o de m√©tricas no tempo\n",
    "- Para horizontes de previs√£o $h$, avalia-se uma m√©trica $m$ (ex.: RMSE, MAE, MAPE, AUC) em cada itera√ß√£o e agrega-se:\n",
    "  $$\n",
    "  \\widehat{m} = \\frac{1}{S} \\sum_{s=1}^{S} m_s\n",
    "  $$\n",
    "  onde $S$ √© o n√∫mero de splits walk-forward. Intervalos de confian√ßa podem ser obtidos por suposi√ß√µes assint√≥ticas ou por *block bootstrap*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681023ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<-- [**Anterior: Matem√°tica para ML**](../01_Introducao_ML/03_matematica_ml.ipynb) | [**Pr√≥ximo: M√©tricas de Classifica√ß√£o**](02_metricas_classificacao.ipynb) -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
