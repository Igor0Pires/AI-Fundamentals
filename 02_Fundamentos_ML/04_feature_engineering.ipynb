{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c01f8ee",
   "metadata": {},
   "source": [
    "# **Feature Engineering ‚Äî M√≥dulo 2, Notebook 4/4**\n",
    "\n",
    "---\n",
    "\n",
    "## √çndice\n",
    "\n",
    "1. [Introdu√ß√£o](#introducao)\n",
    "2. [Encoding](#encoding)\n",
    "3. [Scaling](#scaling)\n",
    "4. [Padroniza√ß√£o](#padronizacao)\n",
    "5. [Imputa√ß√£o de valores ausentes](#imputacao)\n",
    "6. [Cria√ß√£o de novas features](#criacao-features)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='introducao'></a>\n",
    "\n",
    "A Feature Engineering √© o processo de extra√ß√£o, manipula√ß√£o e transforma√ß√£o de dados brutos, permitindo que esses dados se transformem em vari√°veis que um modelo de machine learning pode usar para alcan√ßar um objetivo desejado. A engenharia de recursos √© um desafio porque envolve uma combina√ß√£o de an√°lise de dados, conhecimento do dom√≠nio de neg√≥cios e certa intui√ß√£o.\n",
    "\n",
    "Pense que dados, por si s√≥, podem n√£o significar muita coisa. Esse problema se torna ainda mais agravante nos dias atuais quando pensamos na quantidade massiva de dados gerados na era do big data. Mais do que nunca, temos um mar de dados a nossa disposi√ß√£o. Por√©m, devemos pensar, como tirar valor disso? Podemos pensar no processo de **feature engineering** de forma abrangente, como a maneira de transformar **dados** em **informa√ß√£o**.\n",
    "\n",
    "Uma analogia √© imaginar o trabalho de um minerador de ouro. Ele extrai rochas brutas (dados) e precisa process√°-las para encontrar o ouro (informa√ß√£o √∫til). Do mesmo modo, a Feature Engineering extrai informa√ß√µes valiosas dos dados e traduz em uma linguagem que o modelo de machine learning consiga ler.\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://www.kdnuggets.com/wp-content/uploads/Feature-Engineering.png\" width=600></img>\n",
    "</p>\n",
    "\n",
    "Existem algumas recomenda√ß√µes para uma feature engineering que sempre devemos seguir e iremos abordar elas nos pr√≥ximos t√≥picos. Por√©m, √© necess√°rio termos em mente que boa parte do processo de feature engineering vai variar em cada situa√ß√£o espec√≠fica e boa parte dela vem de termos criatividade e expertise para olharmos para nossos dados e imaginar como podemos extrair valor deles.\n",
    "\n",
    "---\n",
    "\n",
    "<a id='encoding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65780d8b",
   "metadata": {},
   "source": [
    "### **Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94fe081",
   "metadata": {},
   "source": [
    "De longe, a maneira mais comum de se representar vari√°veis categ√≥ricas √© utilizando encoding. Imagine que uma de suas features √© uma coluna de n√≠vel educacional com valores como *Fundamental*, *Ensino M√©dio*, *Superior* e *P√≥s-Gradua√ß√£o*. Lembre-se que os modelos de machine learning s√£o algoritmos matem√°ticos/estat√≠sticos. Dessa forma, n√£o podemos utilizar vari√°veis textuais diretamente no modelo; precisamos traduzir isso em linguagem matem√°tica.\n",
    "\n",
    "\n",
    "#### **One-hot encoding**\n",
    "O m√©todo mais conhecido e utilizado √© o **one-hot encoding** que cria uma coluna bin√°ria para cada categoria. Essas colunas tamb√©m s√£o chamadas de vari√°veis dummies.\n",
    "\n",
    "No nosso exemplo, ter√≠amos uma coluna \"Fundamental\" que receberia valor 1 para cada observa√ß√£o com este n√≠vel educacional e 0 caso contr√°rio, uma coluna \"Ensino M√©dio\" com valor 1 para cada observa√ß√£o com esse n√≠vel educacional e 0 caso contr√°rio, e assim por diante.\n",
    "\n",
    "üìù **Observa√ß√£o**: Devemos ter cuidado ao aplicar o one-hot encoding para n√£o incorrermos no problema de multicolinearidade. Esse problema acontece quando uma coluna pode ser perfeitamente prevista a partir das outras. Isso cria redund√¢ncia nos dados e pode atrapalhar alguns modelos estat√≠sticos, como regress√£o linear, ao tornar os c√°lculos inst√°veis.\n",
    "\n",
    "No nosso exemplo, a √∫ltima coluna (P√≥s-Gradua√ß√£o) pode ser perfeitamente inferida das outras tr√™s, pois: P√≥s-Gradua√ß√£o = 1 ‚àí (Fundamental + Ensino M√©dio + Superior). Para contornar esse problema, basta excluirmos uma coluna ao fazer o one-hot encoding.\n",
    "\n",
    "#### **Label encoding**\n",
    "\n",
    "Outro m√©todo bastante utilizado √© o label encoding. De maneira simples, ele converte os valores de uma vari√°vel categ√≥rica em n√∫meros inteiros. No nosso exemplo, \"Fundamental\" seria convertido para 0, \"Ensino M√©dio\" = 1, \"Superior\" = 2 e \"P√≥s-Gradua√ß√£o\" = 3.\n",
    "\n",
    "üìù **Observa√ß√£o**: Devemos ter cuidado ao utilizar o label encoding porque os modelos podem interpretar essa transforma√ß√£o como uma rela√ß√£o ordinal. Por exemplo, o modelo pode entender que \"P√≥s-Gradua√ß√£o\" (3) √© tr√™s vezes mais importante do que \"Fundamental\" (0), o que pode levar a infer√™ncias incorretas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa97bb",
   "metadata": {},
   "source": [
    "#### **Pr√°tica**\n",
    "\n",
    "Para ilustrar a aplica√ß√£o de encoding em python, iremos importar um novo dataset que possui vari√°veis categoricas.\n",
    "\n",
    "Este dataframe cont√©m dados de tripulantes do titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carrega o dataset\n",
    "titanic = fetch_openml('titanic', version=1, as_frame=True)\n",
    "# Transforma em um DataFrame\n",
    "df_titanic = pd.DataFrame(data=titanic.data, columns=titanic.feature_names)\n",
    "\n",
    "# Adiciona a coluna de classes\n",
    "df_titanic['survived'] = titanic.target\n",
    "\n",
    "# Tradu√ß√£o das colunas para o portugues\n",
    "df_titanic = df_titanic.rename(columns={'pclass': 'Classe',\n",
    "                                        'name': 'Nome',\n",
    "                                        'sex': 'Sexo',\n",
    "                                        'age': 'Idade',\n",
    "                                        'sibsp': 'Irm√£os/C√¥njuges',\n",
    "                                        'parch': 'Pais/Filhos',\n",
    "                                        'ticket': 'Bilhete',\n",
    "                                        'fare': 'Tarifa',\n",
    "                                        'cabin': 'Cabine',\n",
    "                                        'embarked': 'Embarque',\n",
    "                                        'boat': 'Bote',\n",
    "                                        'body': 'Corpo',\n",
    "                                        'home.dest': 'Destino',\n",
    "                                        'survived': 'Sobreviveu'\n",
    "                                        })\n",
    "\n",
    "# E exibe as 5 primeiras linhas\n",
    "df_titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a fun√ß√£o de one-hot encoding do sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Instancia o OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "\n",
    "# Aplica o one-hot encoding nas colunas categ√≥ricas\n",
    "categorical_cols = ['Cabine']\n",
    "X_titanic = df_titanic.drop(columns=['Sobreviveu'])\n",
    "y_titanic = df_titanic['Sobreviveu']\n",
    "X_titanic_encoded = encoder.fit_transform(X_titanic[categorical_cols]).toarray()\n",
    "X_titanic_encoded_df = pd.DataFrame(X_titanic_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "X_titanic_encoded_df = pd.concat([X_titanic.drop(columns=categorical_cols).reset_index(drop=True), X_titanic_encoded_df], axis=1)\n",
    "\n",
    "# E exibe as 5 primeiras linhas\n",
    "X_titanic_encoded_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be10bf3",
   "metadata": {},
   "source": [
    "Perceba a quantidade de colunas resultante. Talvez o one hot encoding n√£o seja a melhor maneira de tratar a vari√°vel categorica neste caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a fun√ß√£o de label encoding do sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instancia o LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Aplica o label encoding nas colunas categ√≥ricas\n",
    "categorical_cols = ['Cabine']\n",
    "\n",
    "X_titanic = df_titanic.drop(columns=['Sobreviveu'])\n",
    "y_titanic = df_titanic['Sobreviveu']\n",
    "X_titanic[categorical_cols] = X_titanic[categorical_cols].apply(label_encoder.fit_transform)\n",
    "\n",
    "# E exibe as 5 primeiras linhas\n",
    "X_titanic.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728f5fb",
   "metadata": {},
   "source": [
    "Perceba que agora, a vari√°vel \"Cabine\" n√£o √© mais categorica, e sim n√∫merica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c07e5",
   "metadata": {},
   "source": [
    "### **Scaling**\n",
    "\n",
    "<a id='scaling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c791412",
   "metadata": {},
   "source": [
    "Scaling √© o processo de transformar os valores n√∫mericos de uma base de dados para que eles fiquem dentro de uma mesma escala. Pense em uma base de dados em que temos idade e sal√°rio de v√°rias pessoas. A vari√°vel idade dever√° ter um range com algo em torno de 0 a 100, enquanto o sal√°rio pode ir de 0 a R$ 1.000.000,00 por exemplo. Muitos algoritmos de machine learning s√£o sens√≠veis a escalas diferentes entre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a fun√ß√£o de min max scaling do sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Instancia o MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplica o min max scaling na coluna idade\n",
    "X_titanic = df_titanic.drop(columns=['Sobreviveu'])\n",
    "y_titanic = df_titanic['Sobreviveu']\n",
    "X_titanic['Idade'] = scaler.fit_transform(X_titanic[['Idade']])\n",
    "# E exibe as 5 primeiras linhas\n",
    "X_titanic.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666062d",
   "metadata": {},
   "source": [
    "### **Padroniza√ß√£o**\n",
    "\n",
    "<a id='padronizacao'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b4a8d",
   "metadata": {},
   "source": [
    "Padroniza√ß√£o √© o processo de transformar a **distribui√ß√£o** de uma vari√°vel de modo que ela tenha m√©dia 0 e desvio padr√£o 1. Esse √© um m√©todo que pode ser interessante de usar quando os dados possuem uma distribui√ß√£o normal ou quando h√° outliers, pois a m√©dia e o desvio padr√£o s√£o menos afetados que os valores extremos no Min-Max Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b278d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a fun√ß√£o de normaliza√ß√£o do sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instancia o StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplica a normaliza√ß√£o na coluna idade\n",
    "X_titanic = df_titanic.drop(columns=['Sobreviveu'])\n",
    "y_titanic = df_titanic['Sobreviveu']\n",
    "X_titanic['Idade'] = scaler.fit_transform(X_titanic[['Idade']])\n",
    "\n",
    "# E exibe as 5 primeiras linhas\n",
    "X_titanic.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c1057",
   "metadata": {},
   "source": [
    "### **Imputa√ß√£o de valores ausentes**\n",
    "\n",
    "<a id='imputacao'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d73e9",
   "metadata": {},
   "source": [
    "Imputa√ß√£o de valores ausentes √© preencher lacunas quando certos dados n√£o foram registrados. Ex.: um sensor meteorol√≥gico que falhou em medir a temperatura em algumas horas; um question√°rio online com a cidade deixada em branco; um log de e-commerce sem o tempo de perman√™ncia de certos usu√°rios. Para lidar com isso, pode-se usar m√©dia/mediana (num√©ricos), moda (categ√≥ricos), forward/backward fill em s√©ries temporais, KNN ou modelos de imputa√ß√£o multivariada. Fa√ßa a imputa√ß√£o apenas no conjunto de treino (ou dentro de cada fold) para evitar vazamento de informa√ß√£o e valide o impacto nas m√©tricas do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05635c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo fict√≠cio de dados com valores ausentes\n",
    "df_clientes = pd.DataFrame({\n",
    "    'Idade': [25, np.nan, 42, 31, np.nan],\n",
    "    'Salario': [3000.0, 4500.0, np.nan, 5200.0, 4100.0],\n",
    "    'Cidade': ['A', 'B', None, 'A', None]\n",
    "})\n",
    "\n",
    "# Separa features (X) e alvo (y) apenas como exemplo (suponha que 'Cidade' n√£o seja alvo)\n",
    "X = df_clientes.copy()\n",
    "\n",
    "# Imputa√ß√£o:\n",
    "# - Num√©ricos: m√©dia para Idade, mediana para Salario\n",
    "# - Categ√≥rico: moda para Cidade\n",
    "X['Idade']   = X['Idade'].fillna(X['Idade'].mean())\n",
    "X['Salario'] = X['Salario'].fillna(X['Salario'].median())\n",
    "X['Cidade']  = X['Cidade'].fillna(X['Cidade'].mode().iloc[0])\n",
    "\n",
    "print(\"Valores ausentes ap√≥s a imputa√ß√£o:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Visualiza as 3 primeiras linhas\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fada34",
   "metadata": {},
   "source": [
    "##### üí° Alternativas poss√≠veis:\n",
    "\n",
    "- Imputa√ß√£o por moda \n",
    "\n",
    "- _KNN Imputer_\n",
    "\n",
    "- _Iterative Imputer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1c70b",
   "metadata": {},
   "source": [
    "### **Cria√ß√£o de novas features**\n",
    "\n",
    "<a id='criacao-features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7df6d9",
   "metadata": {},
   "source": [
    "A cria√ß√£o de novas features nada mais √© do que transformar ou combinar vari√°veis para revelar padr√µes que o modelo sozinho talvez n√£o capture. Exemplos comuns incluem: transforma√ß√µes (log, raiz, padroniza√ß√£o), intera√ß√µes (produto/raz√£o entre vari√°veis), agrega√ß√µes temporais (m√©dias m√≥veis), extra√ß√£o de componentes de data (m√™s, dia da semana) e codifica√ß√£o de categ√≥ricas. Sempre crie features usando apenas o treino (ou dentro de cada fold) para evitar vazamento de informa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89795971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo fict√≠cio\n",
    "df = pd.DataFrame({\n",
    "    'Idade':  [22, 35, 41, 29, 33, 26],\n",
    "    'Salario':[2500, 5200, 6800, 3900, 4500, 3100],\n",
    "    'Cidade': ['A', 'B', 'A', 'C', 'B', 'A'],\n",
    "    'Data':   pd.to_datetime(['2025-01-01','2025-01-02','2025-01-03','2025-01-04','2025-01-05','2025-01-06'])\n",
    "})\n",
    "\n",
    "# Trabalhe numa c√≥pia\n",
    "X = df.copy()\n",
    "\n",
    "# 1) Transforma√ß√µes\n",
    "X['log_Salario'] = np.log1p(X['Salario'])              # log(1 + Salario)\n",
    "X['Salario_por_Idade'] = X['Salario'] / (X['Idade']+1) # raz√£o simples (evita div. por zero)\n",
    "\n",
    "# 2) Intera√ß√µes simples\n",
    "X['Idade_x_logSal'] = X['Idade'] * X['log_Salario']\n",
    "\n",
    "# 3) Extra√ß√£o de componentes temporais\n",
    "X['Mes'] = X['Data'].dt.month\n",
    "X['DiaSemana'] = X['Data'].dt.dayofweek  # 0 = segunda\n",
    "\n",
    "# 4) Agrega√ß√µes temporais (ex.: m√©dia m√≥vel de 3 dias do sal√°rio)\n",
    "X = X.sort_values('Data')\n",
    "X['Salario_MM3'] = X['Salario'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# 5) Codifica√ß√£o de categ√≥ricas (one-hot)\n",
    "X = pd.get_dummies(X, columns=['Cidade'], drop_first=True)\n",
    "\n",
    "print(\"Colunas ap√≥s feature engineering:\")\n",
    "print(list(X.columns))\n",
    "\n",
    "print(\"\\nPr√©via dos dados com novas features:\")\n",
    "print(X.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f80295",
   "metadata": {},
   "source": [
    "Esses s√£o alguns m√©todos usuais de feature engineering, mas n√£o s√£o todos. Conforme ressaltado, a depender do problema em quest√£o voc√™ dever√° ter um pingo de criatividade para pensar formas diferentes de extrair informa√ß√£o contida nos dados. Por exemplo, muitas vezes voc√™ pode criar novas vari√°veis fazendo intera√ß√µes de vari√°veis em sua base.\n",
    "\n",
    "Sempre dedique um tempo especial a parte de feature engineering quando estiver desenvolvendo um modelo de machine learning, ela pode ser o diferencial para alcan√ßar um resultado satisfat√≥rio!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787e6a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<-- [**Anterior: M√©tricas de Regress√£o**](03_metricas_regressao.ipynb) | [**Pr√≥ximo: M√≥dulo 3 ‚Äî Classifica√ß√£o**](../03_Classificacao/01_knn.ipynb) -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
