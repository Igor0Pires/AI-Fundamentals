{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Árvores de Decisão para Regressão — Módulo 4, Notebook 3/4**\n",
    "\n",
    "---\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. [Introdução](#introducao)\n",
    "2. [Intuição e Motivação](#intuicao)\n",
    "3. [Construção Manual: Splits Passo-a-Passo](#splits-manuais)\n",
    "4. [Formulação Matemática](#formulacao)\n",
    "5. [Implementação com Sklearn](#sklearn)\n",
    "6. [Visualização da Árvore](#visualizacao-arvore)\n",
    "7. [Feature Importance](#feature-importance)\n",
    "8. [Hiperparâmetros e Grid Search](#hiperparametros)\n",
    "9. [Diagnóstico de Resíduos](#residuos)\n",
    "10. [Comparação com Outros Modelos](#comparacao)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introducao'></a>\n",
    "## **Introdução**\n",
    "Na classificação, cada nó busca uma pergunta que **reduza impureza** (Gini, Entropia) de forma mais agressiva. Já na regressão, o objetivo muda: agora queremos nós (segmentos) onde os valores reais **fiquem concentrados** e o erro seja baixo.\n",
    "\n",
    "Em vez de medir mistura de classes, medimos quão dispersos são os valores numéricos dentro de cada região.\n",
    "\n",
    "Ou seja, para regressão buscamos tipicamente:\n",
    "- Redução da Soma dos Erros Quadráticos (SSE)\n",
    "- Redução da Variância\n",
    "- Mean Squared Error (MSE) dentro dos nós\n",
    "\n",
    "A ideia continua ser escolher o melhor split local, construir recursivamente até parar por algum critério."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intuicao'></a>\n",
    "## **Intuição e Motivação**\n",
    "\n",
    "Vamos manter a ideia da predição do preço de uma casa usando:\n",
    "- Área (m²)\n",
    "- Número de quartos\n",
    "- Idade do imóvel\n",
    "\n",
    "Uma árvore de regressão pensa em \"segmentar\" o espaço em blocos onde o **preço médio** dentro de cada bloco seja uma boa aproximação. Em vez de devolver uma classe na folha, ela devolve um **valor (geralmente a média ou mediana dos valores naquele nó)**.\n",
    "\n",
    "Perguntas sucessivas podem criar regiões cada vez mais homogêneas em termos de preço, ou seja, se segmentarmos demais, memorizamos ruído (overfitting). Se segmentarmos de menos, perdemos estrutura (underfitting).\n",
    "\n",
    "Vamos construir um exemplo sintético com relação não-linear para visualizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================================================\n",
    "# DADOS E VISUALIZAÇÃO INICIAL\n",
    "# =======================================================\n",
    "\n",
    "# Imports principais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree, export_text\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados sintéticos (não-linear + interação)\n",
    "np.random.seed(42)\n",
    "N = 400\n",
    "X1 = np.random.uniform(0, 10, N)          # Ex: área\n",
    "X2 = np.random.uniform(-5, 5, N)           # Ex: idade (centrada)\n",
    "X3 = np.random.uniform(0, 1, N)            # Ex: fator de localização (score)\n",
    "\n",
    "# Relação verdadeira (não linear)\n",
    "# Inclui termo senoidal e interação X1*X3\n",
    "y = 15 + 4*X1 - 2.5*X2 + 10*X3 + 3*np.sin(X1) + 5*X1*X3 + np.random.normal(0, 2.0, N)\n",
    "\n",
    "X = pd.DataFrame({'Area': X1, 'Idade': X2, 'LocalScore': X3})\n",
    "df = X.copy()\n",
    "df['Preco'] = y\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização\n",
    "plt.figure(figsize=(7,5))\n",
    "sc = plt.scatter(df['Area'], df['Preco'], c=df['LocalScore'], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(sc, label='LocalScore')\n",
    "plt.xlabel('Área (m²)')\n",
    "plt.ylabel('Preço')\n",
    "plt.title('Dados Sintéticos - Regressão')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='splits-manuais'></a>\n",
    "\n",
    "## **Construção Manual: Splits Passo-a-Passo**Vamos construir uma árvore de decisão manualmente, calculando SSE e ganho de informação em cada split. Começaremos com um split de `LocalScore > 0.5` criando duas folhas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def sse(y):\n",
    "    return ((y - y.mean())**2).sum() # Soma dos erros ao quadrado\n",
    "\n",
    "# split por LocalScore > 0.5\n",
    "threshold_local = 0.5\n",
    "grupo_esq = df[df['LocalScore'] <= threshold_local]\n",
    "grupo_dir = df[df['LocalScore'] > threshold_local]\n",
    "\n",
    "baseline_sse = sse(df['Preco'])\n",
    "baseline_mse = ((df['Preco'] - df['Preco'].mean())**2).mean()\n",
    "\n",
    "split_sse = sse(grupo_esq['Preco']) + sse(grupo_dir['Preco'])\n",
    "gain_1 = baseline_sse - split_sse\n",
    "split_mse = split_sse / len(df)\n",
    "\n",
    "pred_manual1 = np.where(df['LocalScore'] > threshold_local, grupo_dir['Preco'].mean(), grupo_esq['Preco'].mean())\n",
    "rmse1 = mean_squared_error(df['Preco'], pred_manual1)\n",
    "mae1 = mean_absolute_error(df['Preco'], pred_manual1)\n",
    "r2_1 = r2_score(df['Preco'], pred_manual1)\n",
    "\n",
    "print('=== Árvore ===')\n",
    "print(f'Tamanho total: {len(df)} | Esq: {len(grupo_esq)} | Dir: {len(grupo_dir)}')\n",
    "print(f'Média Global: {df['Preco'].mean():.3f}')\n",
    "print(f'Média Esq (LS<=0.5): {grupo_esq['Preco'].mean():.3f}')\n",
    "print(f'Média Dir (LS>0.5): {grupo_dir['Preco'].mean():.3f}')\n",
    "print('\\nSSE Baseline:', f'{baseline_sse:.2f}')\n",
    "print('SSE Pós-Split:', f'{split_sse:.2f}')\n",
    "print('Gain (redução SSE):', f'{gain_1:.2f}')\n",
    "print('\\nMSE Baseline:', f'{baseline_mse:.3f}')\n",
    "print('MSE Pós-Split:', f'{split_mse:.3f}')\n",
    "print('\\nMétricas predição (2 folhas):')\n",
    "print(f'RMSE: {rmse1:.3f} | MAE: {mae1:.3f} | R²: {r2_1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como Interpretar os Resultados do Split Manual\n",
    "\n",
    "**SSE (Sum of Squared Errors):**\n",
    "- **Baseline SSE:** Erro total quando usamos apenas a média global (sem splits)\n",
    "- **Pós-Split SSE:** Erro total após dividir em dois grupos\n",
    "- **Gain (Redução):** Quanto o split reduziu o erro. Maior = melhor split\n",
    "\n",
    "**Grupos criados:**\n",
    "- Cada grupo tem sua própria média como predição\n",
    "- Grupos mais homogêneos (baixa variância interna) = predições mais precisas\n",
    "\n",
    "**Métricas finais:**\n",
    "- **R²:** Percentual da variância explicada (0 a 1, maior = melhor)\n",
    "- **RMSE:** Erro médio em unidades originais (menor = melhor)\n",
    "- Comparar sempre com baseline (média global) para avaliar ganho real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo nível: adicionar split por Area > 5 dentro de cada lado\n",
    "threshold_area = 5\n",
    "L_esq = df[(df['LocalScore'] <= threshold_local) & (df['Area'] <= threshold_area)]\n",
    "L_esq_2 = df[(df['LocalScore'] <= threshold_local) & (df['Area'] > threshold_area)]\n",
    "L_dir = df[(df['LocalScore'] > threshold_local) & (df['Area'] <= threshold_area)]\n",
    "L_dir_2 = df[(df['LocalScore'] > threshold_local) & (df['Area'] > threshold_area)]\n",
    "\n",
    "sse_4 = sse(L_esq['Preco']) + sse(L_esq_2['Preco']) + sse(L_dir['Preco']) + sse(L_dir_2['Preco'])\n",
    "gain_total_2 = baseline_sse - sse_4\n",
    "gain_incremental_2 = split_sse - sse_4\n",
    "\n",
    "mean_L_esq = L_esq['Preco'].mean()\n",
    "mean_L_esq_2 = L_esq_2['Preco'].mean()\n",
    "mean_L_dir = L_dir['Preco'].mean()\n",
    "mean_L_dir_2 = L_dir_2['Preco'].mean()\n",
    "\n",
    "def predict_row_manual2(row):\n",
    "    if row['LocalScore'] <= threshold_local:\n",
    "        if row['Area'] <= threshold_area:\n",
    "            return mean_L_esq\n",
    "        else:\n",
    "            return mean_L_esq_2\n",
    "    else:\n",
    "        if row['Area'] <= threshold_area:\n",
    "            return mean_L_dir\n",
    "        else:\n",
    "            return mean_L_dir_2\n",
    "\n",
    "pred_manual2 = df.apply(predict_row_manual2, axis=1).values\n",
    "rmse2 = mean_squared_error(df['Preco'], pred_manual2)\n",
    "mae2 = mean_absolute_error(df['Preco'], pred_manual2)\n",
    "r2_2 = r2_score(df['Preco'], pred_manual2)\n",
    "\n",
    "print('\\n=== Árvore 2 ===')\n",
    "print('Tamanhos folhas:', len(L_esq), len(L_esq_2), len(L_dir), len(L_dir_2))\n",
    "print(f'SSE 1º nível: {split_sse:.2f}')\n",
    "print(f'SSE 2º nível: {sse_4:.2f}')\n",
    "print(f'Gain acumulado total: {gain_total_2:.2f}')\n",
    "print(f'Gain incremental segundo nível: {gain_incremental_2:.2f}')\n",
    "print('\\nMédias por folha:')\n",
    "print(f'  (LS<=0.5, A<=5): {mean_L_esq:.3f}')\n",
    "print(f'  (LS<=0.5, A>5): {mean_L_esq_2:.3f}')\n",
    "print(f'  (LS>0.5, A<=5): {mean_L_dir:.3f}')\n",
    "print(f'  (LS>0.5, A>5): {mean_L_dir_2:.3f}')\n",
    "print('\\nMétricas predição (4 folhas):')\n",
    "print(f'RMSE: {rmse2:.3f} | MAE: {mae2:.3f} | R²: {r2_2:.3f}')\n",
    "print('\\nEvolução RMSE:', f'{rmse1:.3f} -> {rmse2:.3f}')\n",
    "print('Evolução R²  :', f'{r2_1:.3f} -> {r2_2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='formulacao'></a>\n",
    "## **Formulação Matemática**\n",
    "\n",
    "A árvore de regressão é MUITO parecida com a da classificação, só trocamos a métrica de impureza de classe por uma métrica de dispersão de valores.\n",
    "\n",
    "**Entrada**\n",
    "\n",
    "1. Conjunto de treinamento de n amostras em pares $ D=\\{(x^{(i)}, y^{(i)})\\}_{i=1}^n $\n",
    "\n",
    "    onde:\n",
    "\n",
    "    - $ x^{(i)} $: vetor de d features ($ x^{(i)} = (x^{(i)}_1, x^{(i)}_2, ..., x^{(i)}_d) $).\n",
    "\n",
    "    - $ y^{(i)} $: rótulo numérico contínuo, ou seja, $ y^{(i)} \\in \\mathbb{R} $.\n",
    "\n",
    "**Processamento**\n",
    "\n",
    "O algoritmo constrói a árvore de forma recursiva, procurando em cada nó a melhor divisão possível. A \"melhor\" divisão é aquela que torna os subconjuntos resultantes o mais homogêneos possível em relação ao valor de $ y $.\n",
    "\n",
    "**1. Critério de 'Impureza' para Regressão (Dispersão)**\n",
    "\n",
    "Em vez de medir a mistura de classes (Gini/Entropia), medimos a dispersão dos valores numéricos dentro de um nó. O critério mais comum é a ja conhecida **Soma dos Erros Quadráticos (SSE - Sum of Squared Errors)**, que é minimizada quando os valores em um nó estão próximos uns dos outros.\n",
    "\n",
    "Para um nó $ S $, o SSE é calculado em relação à média dos valores ($ \\bar{y}_S $) daquele nó:\n",
    "\n",
    "$$SSE(S) = \\sum_{i \\in S} (y^{(i)} - \\bar{y}_S)^2$$\n",
    "\n",
    "Um nó com baixo SSE é considerado \"puro\" no contexto da regressão.\n",
    "\n",
    "**2. Ganho na Divisão (Redução de Variância)**\n",
    "\n",
    "De forma análoga ao *Information Gain*, o algoritmo escolhe a divisão que maximiza a **redução do SSE**. Para uma feature $ A $ que divide o nó $ S $ em subconjuntos $ S_L $ (esquerda) e $ S_R $ (direita), o ganho é:\n",
    "$$ \\text{Redução de SSE} = SSE(S) - (SSE(S_L) + SSE(S_R))$$\n",
    "\n",
    "O algoritmo testa todas as features e todos os possíveis pontos de corte para encontrar a divisão que resulta na maior redução de SSE.\n",
    "\n",
    "**3. Algoritmo de Construção**\n",
    "\n",
    "O processo é o mesmo da classificação, mas usando a métrica de regressão:\n",
    "\n",
    "```\n",
    "função BuildTree(S, Features):\n",
    "    se critério de parada for atingido (ex: profundidade máxima):\n",
    "        retorna folha com o valor médio de y em S\n",
    "    \n",
    "    seleciona feature A e threshold t que maximizam a Redução de SSE\n",
    "    cria nó com o teste (A <= t)\n",
    "    \n",
    "    S_L, S_R = divide S baseado no teste\n",
    "    \n",
    "    adiciona subárvore esquerda BuildTree(S_L, Features)\n",
    "    adiciona subárvore direita BuildTree(S_R, Features)\n",
    "```\n",
    "\n",
    "**4. Critérios de Parada**\n",
    "\n",
    "Idênticos aos da classificação, usados para regularizar a árvore e evitar overfitting:\n",
    "- Profundidade máxima da árvore (`max_depth`).\n",
    "- Número mínimo de amostras para dividir um nó (`min_samples_split`).\n",
    "- Número mínimo de amostras em um nó folha (`min_samples_leaf`).\n",
    "\n",
    "**Saída - Regressão**\n",
    "\n",
    "- **Estrutura da Árvore**: Um conjunto de nós com regras de divisão.\n",
    "- **Predição**: Para uma nova amostra, ela percorre a árvore de acordo com as regras até chegar a um nó folha. O valor da predição é o **valor médio** de $ y $ das amostras de treinamento que caíram naquela folha durante a construção da árvore.\n",
    "\n",
    "**Poda (Pruning)**\n",
    "\n",
    "O conceito de pré-poda (usando critérios de parada) e pós-poda para controlar a complexidade e evitar overfitting é exatamente o mesmo aplicado às árvores de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.25, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sklearn'></a>\n",
    "## **Implementação com Sklearn**\n",
    "\n",
    "Vamos treinar uma árvore de regressão simples e observar métricas:\n",
    "- RMSE\n",
    "- MAE\n",
    "- R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treino simples\n",
    "reg = DecisionTreeRegressor(random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, pred)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "r2 = r2_score(y_test, pred)\n",
    "print(f\"RMSE: {rmse:.3f} | MAE: {mae:.3f} | R²: {r2:.3f}\")\n",
    "\n",
    "# Visualização: real vs predito\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(y_test, pred, alpha=0.6)\n",
    "plt.xlabel('Real')\n",
    "plt.ylabel('Predito')\n",
    "plt.title('Real vs Predito - Árvore Regressão')\n",
    "lims = [min(y_test.min(), pred.min()), max(y_test.max(), pred.max())]\n",
    "plt.plot(lims, lims, 'r--') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretando o Gráfico Real vs Predito\n",
    "\n",
    "**O que procurar:**\n",
    "- **Pontos na diagonal vermelha:** Predição perfeita (real = predito)\n",
    "- **Dispersão em torno da diagonal:** Indica qualidade do ajuste\n",
    "  - Dispersão pequena = bom modelo\n",
    "  - Dispersão grande = modelo fraco\n",
    "- **Padrões sistemáticos:** Se pontos formam curva, modelo não captura toda a estrutura\n",
    "- **Outliers afastados:** Pontos muito distantes da diagonal podem indicar dados anômalos\n",
    "\n",
    "**Métricas complementares:**\n",
    "- **RMSE < 3.0:** Excelente para este problema\n",
    "- **R² > 0.90:** Modelo explica mais de 90% da variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualizacao-arvore'></a>\n",
    "## **Visualização da Árvore**\n",
    "\n",
    "Uma das grandes vantagens das árvores de decisão é a interpretabilidade. Podemos visualizar graficamente a estrutura completa da árvore e extrair as regras de decisão em formato textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# VISUALIZAÇÃO DA ESTRUTURA DA ÁRVORE\n",
    "# =======================================================\n",
    "\n",
    "# Visualizar árvore completa\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(reg, \n",
    "          feature_names=['Area', 'Idade', 'LocalScore'],\n",
    "          filled=True, \n",
    "          rounded=True, \n",
    "          fontsize=10)\n",
    "plt.title('Estrutura da Árvore de Regressão (sem poda) (que lindo!)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Regras textuais\n",
    "print(\"\\n=== Regras da Árvore (Texto) ===\")\n",
    "tree_rules = export_text(reg, feature_names=['Area', 'Idade', 'LocalScore'])\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando a Predição em Degraus\n",
    "\n",
    "Uma característica fundamental das Árvores de Decisão é que suas predições são feitas em \"degraus\". Isso significa que a árvore divide o espaço de features em regiões retangulares, e dentro de cada região, a predição é um valor constante (a média dos valores de treinamento naquela região).\n",
    "\n",
    "Vamos visualizar isso com um exemplo simples usando apenas uma feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N_viz = 400\n",
    "X1_viz = np.random.uniform(0, 10, N_viz) # Ex: área\n",
    "X_1d = X1_viz.reshape(-1, 1)\n",
    "noise_viz = np.random.normal(0, 2.0, N_viz)\n",
    "y_1d = 15 + 4*X1_viz + 3*np.sin(X1_viz) + noise_viz \n",
    "\n",
    "\n",
    "X_train_1d, X_test_1d, y_train_1d, y_test_1d = train_test_split(X_1d, y_1d, test_size=0.25, random_state=42)\n",
    "\n",
    "# Treinar uma Árvore de Decisão de Regressão com profundidade limitada\n",
    "tree_reg_1d = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "tree_reg_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Gerar pontos para plotar a função de degraus\n",
    "X_plot_1d = np.linspace(X_1d.min(), X_1d.max(), 500).reshape(-1, 1)\n",
    "y_plot_1d = tree_reg_1d.predict(X_plot_1d)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_1d, y_1d, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"Dados Reais\")\n",
    "plt.plot(X_plot_1d, y_plot_1d, color=\"cornflowerblue\", label=\"Predição da Árvore (degraus)\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Feature Única (Ex: Área)\")\n",
    "plt.ylabel(\"Target (Ex: Preço)\")\n",
    "plt.title(\"Visualização da Predição em Degraus de uma Árvore de Regressão\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature-importance'></a>\n",
    "## **Feature Importance**\n",
    "\n",
    "Árvores de decisão calculam automaticamente a importância de cada feature baseada em quanto ela contribui para reduzir o SSE nos splits. Features que aparecem mais cedo na árvore (próximo à raiz) e que produzem maiores ganhos tendem a ter maior importância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir grid de hiperparâmetros e executar Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['squared_error', 'friedman_mse']\n",
    "}\n",
    "\n",
    "reg_base = DecisionTreeRegressor(random_state=42)\n",
    "grid = GridSearchCV(reg_base, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=0)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Melhores parâmetros:', grid.best_params_)\n",
    "print('Melhor R² (CV):', f'{grid.best_score_:.4f}')\n",
    "\n",
    "best = grid.best_estimator_\n",
    "pred_best = best.predict(X_test)\n",
    "\n",
    "print(f'\\nR² teste: {r2_score(y_test, pred_best):.4f}')\n",
    "print(f'RMSE teste: {np.sqrt(mean_squared_error(y_test, pred_best)):.3f}')\n",
    "print(f'MAE teste: {mean_absolute_error(y_test, pred_best):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# IMPORTÂNCIA DAS FEATURES\n",
    "# =======================================================\n",
    "\n",
    "# Usar modelo otimizado do Grid Search\n",
    "importances = best.feature_importances_\n",
    "feature_names = ['Area', 'Idade', 'LocalScore']\n",
    "\n",
    "# Ordenar por importância\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(len(importances)), importances[indices], color='steelblue', edgecolor='black')\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importância')\n",
    "plt.title('Feature Importance - Árvore de Decisão')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "for i in indices:\n",
    "    print(f\"{feature_names[i]:12s}: {importances[i]:.4f}\")\n",
    "\n",
    "print(\"\\n--- Interpretação ---\")\n",
    "print(\"Importância indica quanto cada feature contribui para reduzir SSE nos splits.\")\n",
    "print(f\"'{feature_names[indices[0]]}' é a mais importante (usada nos splits principais).\")\n",
    "print(f\"Se alguma feature tem importância ~0, ela não foi usada em nenhum split.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hiperparametros'></a>\n",
    "## **Hiperparâmetros e Grid Search**\n",
    "\n",
    "Vamos buscar combinação que maximize R² com validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3,5,7,None],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,2,5],\n",
    "    'criterion': ['squared_error','friedman_mse']\n",
    "}\n",
    "reg_base = DecisionTreeRegressor(random_state=42)\n",
    "grid = GridSearchCV(reg_base, param_grid, cv=5, scoring='r2', n_jobs=-1, verbose=0)\n",
    "grid.fit(X_train, y_train)\n",
    "print('Melhores parâmetros:', grid.best_params_)\n",
    "print('Melhor R2 CV:', grid.best_score_)\n",
    "\n",
    "best = grid.best_estimator_\n",
    "pred_best = best.predict(X_test)\n",
    "print('R2 teste:', r2_score(y_test, pred_best))\n",
    "print('RMSE teste:', mean_squared_error(y_test, pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretando Resultados do Grid Search\n",
    "\n",
    "**Melhores parâmetros encontrados:**\n",
    "- **max_depth:** Controla profundidade máxima. Valores menores = mais generalização\n",
    "- **min_samples_split:** Mínimo para dividir nó. Valores maiores = árvore mais conservadora\n",
    "- **min_samples_leaf:** Mínimo em folha. Evita folhas com poucos pontos (reduz overfitting)\n",
    "- **criterion:** Métrica de qualidade do split\n",
    "  - `squared_error`: SSE padrão\n",
    "  - `friedman_mse`: MSE com penalização (melhora em alguns casos)\n",
    "\n",
    "**Melhor score CV vs Teste:**\n",
    "- Se R² CV ≈ R² teste: Modelo generalizando bem\n",
    "- Se R² CV >> R² teste: Possível overfitting (revisar hiperparâmetros)\n",
    "- Se R² CV << R² teste: Sorte no split (executar múltiplas rodadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='residuos'></a>\n",
    "## **Diagnóstico de Resíduos**\n",
    "\n",
    "Resíduos = real - predito. Devem estar centrados em zero e sem padrão claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = y_test - pred_best\n",
    "fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
    "\n",
    "# Scatter residuos vs predito\n",
    "axes[0].scatter(pred_best, res, alpha=0.6)\n",
    "axes[0].axhline(0, color='red', linestyle='--')\n",
    "axes[0].set_xlabel('Predito')\n",
    "axes[0].set_ylabel('Resíduo')\n",
    "axes[0].set_title('Resíduo vs Predito')\n",
    "\n",
    "# Histograma\n",
    "axes[1].hist(res, bins=20, edgecolor='k')\n",
    "axes[1].set_xlabel('Resíduo')\n",
    "axes[1].set_ylabel('Freq')\n",
    "axes[1].set_title('Distribuição Resíduos')\n",
    "\n",
    "# QQ plot\n",
    "import scipy.stats as stats\n",
    "stats.probplot(res, dist=\"norm\", plot=axes[2])\n",
    "axes[2].set_title('Q-Q Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretando a Análise de Resíduos\n",
    "\n",
    "**Gráfico 1: Resíduo vs Predito**\n",
    "- **Ideal:** Pontos distribuídos aleatoriamente em torno de zero, sem padrão\n",
    "- **Padrão em forma de funil:** Heteroscedasticidade (variância não constante)\n",
    "- **Padrão curvo:** Modelo não capturou relação não-linear\n",
    "- **Outliers:** Pontos muito afastados (> 3 desvios padrão)\n",
    "\n",
    "**Gráfico 2: Histograma**\n",
    "- **Ideal:** Distribuição aproximadamente normal centrada em zero\n",
    "- **Assimétrico:** Modelo tende a super/subestimar sistematicamente\n",
    "- **Bimodal:** Pode indicar dois regimes diferentes nos dados\n",
    "\n",
    "**Gráfico 3: Q-Q Plot**\n",
    "- **Ideal:** Pontos seguem linha diagonal\n",
    "- **Desvios nas pontas:** Caudas pesadas (outliers)\n",
    "- **Desvios no centro:** Distribuição não-normal\n",
    "\n",
    "**Estatísticas:**\n",
    "- **Média ~0:** Resíduos não enviesados (desejável)\n",
    "- **Desvio padrão:** Quanto menor, melhor o ajuste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='comparacao'></a>\n",
    "## **Comparação com Outros Modelos**\n",
    "\n",
    "Para avaliar se a complexidade adicional de uma árvore de decisão é justificada, vamos compará-la com modelos mais simples como baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# COMPARAÇÃO: ÁRVORE VS REGRESSÃO LINEAR VS SVR\n",
    "# =======================================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# 1. Regressão Linear (baseline simples)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "# 2. SVR RBF (baseline não-linear)\n",
    "svr = SVR(kernel='rbf', C=10, epsilon=0.1, gamma='scale')\n",
    "svr.fit(X_train, y_train)\n",
    "pred_svr = svr.predict(X_test)\n",
    "\n",
    "# 3. Árvore otimizada (já temos: best e pred_best)\n",
    "\n",
    "# Comparar métricas\n",
    "results = pd.DataFrame({\n",
    "    'Modelo': ['Regressão Linear', 'SVR (RBF)', 'Árvore de Decisão'],\n",
    "    'RMSE': [\n",
    "        np.sqrt(mean_squared_error(y_test, pred_lr)),\n",
    "        np.sqrt(mean_squared_error(y_test, pred_svr)),\n",
    "        np.sqrt(mean_squared_error(y_test, pred_best))\n",
    "    ],\n",
    "    'MAE': [\n",
    "        mean_absolute_error(y_test, pred_lr),\n",
    "        mean_absolute_error(y_test, pred_svr),\n",
    "        mean_absolute_error(y_test, pred_best)\n",
    "    ],\n",
    "    'R²': [\n",
    "        r2_score(y_test, pred_lr),\n",
    "        r2_score(y_test, pred_svr),\n",
    "        r2_score(y_test, pred_best)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Comparação de Modelos ===\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- Análise ---\")\n",
    "best_model = results.loc[results['R²'].idxmax(), 'Modelo']\n",
    "print(f\"Melhor modelo (R²): {best_model}\")\n",
    "\n",
    "if results.loc[2, 'R²'] > results.loc[0, 'R²']:\n",
    "    print(\"Árvore superou linear → dados contêm relações não-lineares e interações\")\n",
    "else:\n",
    "    print(\"Linear competitivo → relação aproximadamente linear\")\n",
    "    \n",
    "print(\"\\nObservação: Árvores únicas são sensíveis a ruído.\")\n",
    "print(\"Para produção, considere ensembles (Random Forest, XGBoost).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusoes'></a>\n",
    "## **Conclusões e Dicas Práticas**\n",
    "\n",
    "**Vantagens de Árvores de Decisão para Regressão**\n",
    "\n",
    "1. **Interpretabilidade**: Modelo \"caixa branca\". Podemos visualizar regras de decisão (plot_tree, export_text).\n",
    "2. **Sem premissas de distribuição**: Não assume linearidade nem normalidade de resíduos.\n",
    "3. **Lida com interações naturalmente**: Captura relações não-lineares e interações sem engineering manual.\n",
    "4. **Facilidade com dados mistos**: Features contínuas e categóricas sem transformações elaboradas (basta codificação simples).\n",
    "5. **Rápida para treinar e prever**: Complexidade log(N) na predição quando balanceada.\n",
    "\n",
    "**Desvantagens**\n",
    "\n",
    "1. **Overfitting**: Sem regularização (max_depth, min_samples_leaf), tende a memorizar ruído.\n",
    "2. **Instabilidade**: Pequenas mudanças nos dados alteram radicalmente a estrutura da árvore.\n",
    "3. **Predições em degrau**: Árvore divide espaço em blocos. Dentro de cada bloco, predição é constante (média). Não suaviza bem limites.\n",
    "4. **Pobre extrapolação**: Fora do range treinado, repetirá média da folha mais próxima (sem extrapolação linear).\n",
    "5. **Tendência a viés em features com mais valores únicos**: Similar à classificação.\n",
    "\n",
    "**Dicas Práticas**\n",
    "\n",
    "- Comece com `max_depth` entre 3 e 7, depois ajuste com cross-validation.\n",
    "- Use `min_samples_split` e `min_samples_leaf` para evitar folhas com poucos pontos (reduz variância).\n",
    "- `criterion='absolute_error'` mais robusto se há outliers fortes.\n",
    "- Observe resíduos: padrão forte indica má captura da estrutura ou necessidade de features adicionais.\n",
    "- **Ensemble > Árvore Única**: Random Forest e Gradient Boosting (XGBoost, LightGBM) são superiores na prática ao combinar múltiplas árvores, reduzindo variância e melhorando generalização.\n",
    "\n",
    "---\n",
    "\n",
    "<-- [**Anterior: SVR**](02_svr.ipynb) | [**Próximo: Ensembles de Regressão**](04_ensembles_regressao.ipynb) -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
