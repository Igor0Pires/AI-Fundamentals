# Módulo 4: Regressão

## Visão geral do módulo

### Contexto
Este módulo apresenta os **principais algoritmos de regressão** utilizados para prever valores contínuos. Enquanto o Módulo 3 focava em "categorizar" (classificação), aqui aprendemos a "estimar quantidades" — preços de casas, valores de ações, temperaturas, vendas futuras, etc. Você aprenderá desde a **Regressão Linear Múltipla** (simples e interpretável) até **técnicas avançadas** como SVR, Árvores de Regressão e Ensembles. Cada abordagem tem trade-offs diferentes entre simplicidade, interpretabilidade e poder preditivo. Este módulo o equipará para resolver problemas de **predição de valores contínuos** em cenários reais.

### Estrutura
Este módulo contém **4 notebooks**:

1. **01_regressao_linear_multipla.ipynb** — Regressão Linear Múltipla
   - Equação normal e solução analítica
   - Interpretação de coeficientes
   - Análise de multicolinearidade
   - Implementação do zero vs Scikit-Learn

2. **02_svr.ipynb** — Support Vector Regression (SVR)
   - Regressão por margem (epsilon-insensitive)
   - Kernel trick para relações não-lineares
   - Regularização e tuning de hiperparâmetros
   - Comparação com regressão linear

3. **03_arvores_regressao.ipynb** — Árvores de Regressão
   - Construção de árvores por particionamento recursivo
   - Redução de variância em folhas
   - Controle de profundidade
   - Visualização e interpretação

4. **04_ensembles_regressao.ipynb** — Métodos Ensemble para Regressão
   - Random Forest Regressor
   - Gradient Boosting Regressor
   - Stacking e Voting
   - Feature importance

### Tempo Estimado
- **Notebook 1 (Regressão Linear Múltipla):** 50-70 minutos (matemática + implementação)
- **Notebook 2 (SVR):** 45-60 minutos (kernels + tuning)
- **Notebook 3 (Árvores de Regressão):** 40-55 minutos (recursão + visualização)
- **Notebook 4 (Ensemble):** 50-70 minutos (combinação de modelos)
- **Total do Módulo:** 3h45min - 4h55min

---

## Fontes (bibliografia principal)
- Géron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems (3rd ed.). O'Reilly Media.

- [Multiple Linear Regression using Python - ML](https://www.geeksforgeeks.org/machine-learning/ml-multiple-linear-regression-using-python/). GeeksforGeeks.
- [Support Vector Regression (SVR) using Linear and Non-Linear Kernels in Scikit Learn](https://www.geeksforgeeks.org/machine-learning/support-vector-regression-svr-using-linear-and-non-linear-kernels-in-scikit-learn/). GeeksforGeeks.
- [Ensemble Learning](https://www.geeksforgeeks.org/machine-learning/a-comprehensive-guide-to-ensemble-learning/). GeeksforGeeks.
- [Gradient Boosting in ML](https://www.geeksforgeeks.org/machine-learning/ml-gradient-boosting/#). GeeksforGeeks.
- [Multiple Linear Regression With scikit-learn](https://www.geeksforgeeks.org/machine-learning/multiple-linear-regression-with-scikit-learn/). GeeksforGeeks.
- [What is Unsupervised Learning](https://www.geeksforgeeks.org/machine-learning/unsupervised-learning/). GeeksforGeeks.

---

## Saber mais (leituras complementares)

- [Machine Learning](https://www.geeksforgeeks.org/machine-learning/). GeeksForGeeks

---

## Palavras-chave do módulo
- Regressão Linear Múltipla
- Equação Normal
- Coeficientes de Regressão
- Multicolinearidade
- MSE (Mean Squared Error)
- RMSE (Root Mean Squared Error)
- R² (Coeficiente de Determinação)
- Resíduos
- Support Vector Regression (SVR)
- Kernel Trick
- Árvore de Regressão
- Random Forest
- Gradient Boosting
- Feature Importance

---

## Autores

- Igor Pires Ferreira
- Maisa Lumi Sonoda


---
