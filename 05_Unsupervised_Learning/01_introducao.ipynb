{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72e2b5a",
   "metadata": {},
   "source": [
    "# **Introdução ao Aprendizado Não-Supervisionado - Módulo 5, Notebook 1/3**\n",
    "\n",
    "---\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. [O que é Aprendizado Não-Supervisionado?](#o-que-e)\n",
    "2. [Estrutura deste Módulo](#estrutura)\n",
    "3. [Aplicações Práticas](#aplicacoes)\n",
    "4. [Desafios e Cuidados](#desafios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911670a",
   "metadata": {},
   "source": [
    "<a id='o-que-e'></a>\n",
    "## 1. O que é Aprendizado Não-Supervisionado?\n",
    "\n",
    "Nos módulos 3 e 4 trabalhamos com aprendizado supervisionado, sempre com rótulos que serviam como \"professor\". Aqui a lógica muda: temos apenas os dados $\\mathbf{X}$ e nenhum $\\mathbf{y}$. O objetivo passa a ser descobrir a estrutura escondida - padrões, agrupamentos, relações e regularidades - sem qualquer resposta pronta.\n",
    "\n",
    "Isso torna as perguntas mais abertas: como agrupar clientes de forma natural, quais dimensões resumem melhor o fenômeno, que padrões surgem em sinais ruidosos, quais pontos parecem estranhos ao resto. É como explorar uma cidade nova sem mapa: você observa a densidade das ruas, identifica bairros, percebe vias principais e atalhos, e só então decide onde vale a pena voltar com mais calma.\n",
    "\n",
    "Esse caráter exploratório é o coração do aprendizado não-supervisionado. Ele revela hipóteses, reduz complexidade e cria insumos que, mais adiante, fortalecem modelos supervisionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a06a73f",
   "metadata": {},
   "source": [
    "<a id='estrutura'></a>\n",
    "## 2. Estrutura deste Módulo\n",
    "\n",
    "O módulo se apoia em dois pilares. No Notebook 2 (Redução de Dimensionalidade) vamos ver como comprimir dados mantendo a essência: PCA como projeção linear rápida e LLE como forma de \"desenrolar\" estruturas não-lineares. Essa etapa é valiosa para visualização, redução de ruído e preparação de dados muito largos antes de treinar modelos supervisionados.\n",
    "\n",
    "No Notebook 3 (Clustering) exploramos como identificar grupos naturais sem rótulos. K-Means oferece centróides rápidos, DBSCAN encontra regiões densas e robustas a formatos diferentes, e GMM dá uma visão probabilística com incerteza. Cada um traz uma noção de similaridade que pode ser convertida em insight de negócio ou em novas features para modelos posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0261f5c",
   "metadata": {},
   "source": [
    "<a id='aplicacoes'></a>\n",
    "## 3. Aplicações Práticas\n",
    "\n",
    "**Análise exploratória e visualização.** Reduzir dimensões para 2D ou 3D (PCA, LLE) permite ver separações, gradientes e outliers que tabelas não mostram. É a etapa de \"olhar nos olhos\" dos dados para gerar hipóteses.\n",
    "\n",
    "**Redução de dimensionalidade e compressão.** Em imagens, textos vetorizados ou dados tabulares com muitas colunas, comprimir para um espaço menor diminui ruído, acelera treino e evita overfitting. No Notebook 2 veremos como decidir quantos componentes manter e o impacto na variância preservada.\n",
    "\n",
    "**Engenharia de features.** No Módulo 2 discutimos criação manual de atributos; aqui usamos UL para gerar atributos automaticamente. Clustering pode produzir rótulos de segmento ou distâncias a centróides que enriquecem modelos supervisionados (ex.: K-Means para grupos geográficos ou de comportamento). Componentes principais também viram features mais informativas e menos redundantes.\n",
    "\n",
    "**Detecção de anomalias.** Modelos baseados em densidade (como DBSCAN) ou projeções que evidenciam pontos isolados ajudam a encontrar fraudes, falhas de sensor ou registros fora do padrão. Mesmo sem rótulos, a estrutura de vizinhança revela outliers.\n",
    "\n",
    "**Recomendação e cold start.** Agrupar itens ou usuários por similaridade cria vizinhanças úteis quando não há histórico suficiente. Clusters servem de base para recomendações iniciais ou para suavizar sparsity em sistemas de recomendação.\n",
    "\n",
    "Essas aplicações mostram que UL não vive isolado: ele prepara terreno, revela padrões e entrega insumos que elevam a qualidade de modelos supervisionados nos módulos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fba85",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[**Anterior: Módulo 4 - Ensembles em Regressão**](../04_Regressao/04_ensembles_regressao.ipynb) | [**Próximo: Redução de Dimensionalidade**](02_dimensionality_reduction.ipynb) →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
